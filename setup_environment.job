#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --job-name=InstallSAM3Venv
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=04:00:00
#SBATCH --output=outputs/env_setup_%A.out

module purge
module load 2025
module load Python/3.11.6

cd $HOME/thesis/Generator_Agnostic_Motion_Based_Deepfake_Detection

# Remove old venv if it exists
rm -rf .venv_sam3

# Create fresh virtual environment
python -m venv .venv_sam3
source .venv_sam3/bin/activate

# Upgrade pip and install PyTorch with CUDA support
python -m pip install --upgrade pip wheel setuptools
python -m pip install torch==2.7.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126

# Install numpy compatible with SAM3 first
pip install "numpy>=1.26,<2.0"

# Clone and install SAM3 from GitHub (includes assets)
git clone https://github.com/facebookresearch/sam3.git temp_sam3
cd temp_sam3
pip install -e .
cd ..

# Install additional dependencies (compatible versions)
pip install opencv-python matplotlib pillow
pip install "scikit-learn<1.6"  # Ensures numpy compatibility

# Clean up
rm -rf temp_sam3

# Load Hugging Face token from .env file
if [ -f .env ]; then
    export $(grep -v '^#' .env | xargs)
fi

# Test SAM3 installation
python -c "
import sam3
from sam3.model_builder import build_sam3_video_predictor
print('✓ SAM3 import successful')
print(f'SAM3 location: {sam3.__file__}')
"

echo "✓ Environment setup complete!"
