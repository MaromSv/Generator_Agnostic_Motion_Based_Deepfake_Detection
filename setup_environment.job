#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --job-name=InstallSAM3Venv
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=04:00:00
#SBATCH --output=outputs/env_setup_%A.out

module purge
module load 2025
module load Python/3.11.6

cd $HOME/thesis/Generator_Agnostic_Motion_Based_Deepfake_Detection

# Remove old venv if it exists
rm -rf .venv_sam3

# Create fresh virtual environment
python -m venv .venv_sam3
source .venv_sam3/bin/activate

# Upgrade pip and install PyTorch with CUDA support
python -m pip install --upgrade pip wheel setuptools
python -m pip install torch==2.7.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126

# Install latest transformers (SAM3 support added recently) and accelerate
pip install git+https://github.com/huggingface/transformers.git
pip install accelerate

# Install additional dependencies
pip install opencv-python matplotlib pillow scikit-learn

# Load Hugging Face token from .env file
if [ -f .env ]; then
    export $(grep -v '^#' .env | xargs)
fi

# Test installation
python -c "
from transformers import Sam3VideoModel, Sam3VideoProcessor
print('✓ Transformers SAM3 import successful')
"

echo "✓ Environment setup complete!"
